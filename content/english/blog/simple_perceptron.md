---
title: "Simple Perceptron"
date: 2020-05-12T12:14:34+06:00
image: "images/portfolio/perceptron.png"
tags: ["Perceptron","MLP", "Neural Networks", "Backpropagation", "Gradient"]
description: "This shows step by steps the backprogation and update of the gradient."
draft: false
---

### Introduction

This post is yet another mini tutorial about MultiLayer Perceptron (MLP), backpropagation gradient techniques techniques. The percetion is the most important unit in a Neural Network. Understanding how this unit works, garantees the understanding a bigger Neural Network. We will describe the working a neuron in a MLP. The history why Artificial Neural Networks can be found everywhere online, but a great paper I would advise would be this one [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf). 

The code is available here: [Simple Perceptron](https://github.com/juliennyambal/perceptron_analytics)


### Opening ...

![Example used](content/english/blog/images/portfolio/perceptron_example.png)

A neuron is the most atomic element in an Artificial Neural Network (ANN). It has some properties:

#### Input Nodes
These are the static nodes in the networks. There are the ones feeding the network with the required inforamtion to perform the thinking. 


#### One More Heading

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore
et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip
ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu
fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt
mollit anim id est laborum.